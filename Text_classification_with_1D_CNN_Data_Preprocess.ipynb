{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## In this notebook, we will preprocess data based on data observation."
      ],
      "metadata": {
        "id": "TVfNHlgfhtsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Info :\n",
        "1. we have total of 20 types of documents(Text files) and total 18828 documents(text files).\n",
        "2. Now our problem is to classify all the documents into any one of the class.\n"
      ],
      "metadata": {
        "id": "MK815G3xhbJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### sample document\n",
        "* Subject: A word of advice\n",
        "* From: jcopelan@nyx.cs.du.edu (The One and Only)\n",
        "* In article < 65882@mimsy.umd.edu > mangoe@cs.umd.edu (Charley Wingate) writes:\n",
        "\n",
        "* I've said 100 times that there is no \"alternative\" that should think you\n",
        "might have caught on by now. And there is no \"alternative\", but the point\n",
        "is, \"rationality\" isn't an alternative either. The problems of metaphysical\n",
        "and religious knowledge are unsolvable-- or I should say, humans cannot\n",
        "solve them.\n",
        "* How does that saying go: Those who say it can't be done shouldn't interrupt\n",
        "those who are doing it.\n",
        "Jim\n",
        "--\n",
        "Have you washed your brain today?"
      ],
      "metadata": {
        "id": "d9tRe6WYhhoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Email-id Preprocess\n",
        "\n",
        "* Find all emails in the document and then get the text after the \"@\". and then split those texts by '.', because ww observe that before \"@\" is mostly organization name or person name.\n",
        "\n",
        "* After that remove the words whose length is less than or equal to 2 and also remove 'com' (occured in all emails) word and then combine those words by space. \n",
        "\n",
        "* In one doc, if we have 2 or more mails, get all, Eg:[test@dm1.d.com, test2@dm2.dm3.com]-->[dm1.d.com, dm3.dm4.com]-->[dm1,d,com,dm2,dm3,com]-> [dm1,dm2,dm3]-->\"dm1 dm2 dm3\" append all those into one list/array. ( This will give length of 18828 sentences i.e one list for each of the document).\n",
        "\n",
        "* In the above sample document there are emails [jcopelan@nyx.cs.du.edu,\n",
        "65882@mimsy.umd.edu, mangoe@cs.umd.edu]\n",
        "\n",
        "preprocessing: [jcopelan@nyx.cs.du.edu, 65882@mimsy.umd.edu, mangoe@cs.umd.edu] ==> [nyx cs du edu mimsy umd edu cs umd edu] ==> [nyx edu mimsy umd edu umd edu]\n",
        "\n",
        "*  Replace all the emails by space in the original text.\n"
      ],
      "metadata": {
        "id": "QFODP-lFkIjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Subject text Preprocess\n",
        "\n",
        "* Get subject of the text i.e. get the total lines where \"Subject:\" occur and remove.\n",
        "\n",
        "* those words which are before the \":\" remove the newlines, tabs, punctuations, any special chars.\n",
        "\n",
        "* Eg: if we have sentance like \"Subject: Re: Gospel Dating @ \\r\\r\\n\" --> You have to get \"Gospel Dating\" Save all this data into another list/array.\n",
        "\n",
        "* After you store it in the list, Replace those sentances in original text by space."
      ],
      "metadata": {
        "id": "I6axNNgUkiLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Text Preprocess Steps\n",
        "\n",
        "* Delete all the sentances where sentence starts with \"Write to:\" or \"From:\".\n",
        "\n",
        "* Delete all the tags like \"< anyword >\"\n",
        "\n",
        "* Delete all the data which are present in the brackets.\n",
        "In many text data, we observed that, they maintained the explanation of sentence\n",
        "or translation of sentence to another language in brackets so remove all those.\n",
        "\n",
        "* Remove all the newlines('\\n'), tabs('\\t'), \"-\", \"\\\". Remove all the words which ends with \":\". Eg: \"Anyword:\"\n",
        "\n",
        "* In the above sample document check the 4nd line, we should remove that \"writes:\"\n",
        "\n",
        "* Decontractions, replace words like below to full words. please check the donors choose preprocessing for this Eg: can't -> can not, 's -> is, i've -> i have, i'm -> i am, you're -> you are, i'll --> i will There is no order to do point 6 to 10. but you have to get final output correctly\n",
        "\n",
        "* Do chunking on the text you have after above preprocessing. Text chunking, also referred to as shallow parsing, is a task that follows Part-Of-Speech\n",
        "Tagging and that adds more structure to the sentence. So it combines the some phrases, named entities into single word. So after that combine all those phrases/named entities by separating \"_\". And remove the phrases/named entities if that is a \"Person\". You can use nltk.ne_chunk to get these.\n",
        "Below we have given one example. please go through it.\n",
        "\n",
        "* Replace all the digits with space i.e delete all the digits.\n",
        "\n",
        "* After doing above points, we observed there might be few word's like\n",
        "\"_word_\" (i.e starting and ending with the _), \"_word\" (i.e starting with the _,\"word_\" (i.e ending with the _) remove the _ from these type of words.\n",
        "\n",
        "* We also observed some words like \"OneLetter_word\"- eg: d_berlin,\n",
        "\"TwoLetters_word\" - eg: dr_berlin , in these words we remove the \"OneLetter_\"(d_berlin ==> berlin) and \"TwoLetters_\" (de_berlin ==> berlin). i.e remove the words which are length less than or equal to 2 after spliiting those words by \"_\".\n",
        "\n",
        "* Convert all the words into lower case and lowe case and remove the words which are greater than or equal to 15 or less than or equal to 2.\n",
        "\n",
        "* replace all the words except \"A-Za-z_\" with space.\n",
        "\n",
        "* Now You got Preprocessed Text, email, subject. create a dataframe with those.\n",
        "Below are the columns of the df."
      ],
      "metadata": {
        "id": "P7y_8Y1HnENa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ShXidLnhVIM"
      },
      "outputs": [],
      "source": [
        "''' Import packages '''\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import os\n",
        "from email.utils import parseaddr\n",
        "from tqdm.notebook import tqdm\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "from nltk.chunk import tree2conlltags\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import Dense, Input, Flatten, Dropout\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.layers import concatenate\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from tensorflow.keras import backend as K\n",
        "import datetime\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow.keras.layers as layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Download few nltk package '''\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "-6YZcRcMhaEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deeb0a91-9a29-4bdf-9163-35db0f1a5058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AolwFzCoqp-",
        "outputId": "66f06cab-23ea-4004-f41b-7d541d70499f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download globe model tokens https://nlp.stanford.edu/projects/glove/\n",
        "!curl --header \"Host: downloads.cs.stanford.edu\" --header \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-US,en;q=0.9\" --header \"Referer: https://nlp.stanford.edu/\" --header \"Cookie: _ga=GA1.2.545929601.1671976005; _gid=GA1.2.2065625101.1671976005; _gat=1\" --header \"Connection: keep-alive\" \"https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\" -L -o \"glove.6B.zip\""
      ],
      "metadata": {
        "id": "NvEtfuDwiFHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b981764b-374d-42ad-e008-089a5e733c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  822M  100  822M    0     0  4485k      0  0:03:07  0:03:07 --:--:-- 3423k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/glove.6B.zip\" -d \"/content/glove\""
      ],
      "metadata": {
        "id": "tkPncZSGiho3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4e09e4-ba72-4318-bf6b-903b98e704eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: /content/glove/glove.6B.50d.txt  \n",
            "  inflating: /content/glove/glove.6B.100d.txt  \n",
            "  inflating: /content/glove/glove.6B.200d.txt  \n",
            "  inflating: /content/glove/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  \"/content/drive/MyDrive/documents.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "z02g57plioMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Preprocess"
      ],
      "metadata": {
        "id": "X7Kf_TRMp41h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This code reference from this link - https://stackoverflow.com/a/31837224/4084039\n",
        "\n",
        "def split_loc(sentence):\n",
        "\n",
        "    '''\n",
        "    Inputs :\n",
        "        name    : sentence\n",
        "        type    : str  \n",
        "    \n",
        "    Ouput : \n",
        "        name    : sentence\n",
        "        type    : str\n",
        "        content : modification on input\n",
        "\n",
        "    Process :\n",
        "        This function take input as string and using pos-tag \n",
        "        check if word is city name then add \"_\" between two words \n",
        "        and return new modified string. \n",
        "    '''\n",
        "\n",
        "    # convert string into tokens\n",
        "    word = nltk.word_tokenize(sentence)\n",
        "\n",
        "    # extract pos tag from strint\n",
        "    pos_tag = nltk.pos_tag(word)\n",
        "\n",
        "    chunk = nltk.ne_chunk(pos_tag)\n",
        "    \n",
        "    old = [ \" \".join(w for w, t in ele) for ele in chunk if isinstance(ele, nltk.Tree)]\n",
        "\n",
        "    # replace underscore\n",
        "    new = [w.replace(w, \"_\".join(w.split())) for w in old]\n",
        "\n",
        "    d = dict(zip(old, new))\n",
        "\n",
        "    # replace new token to old in string\n",
        "    for i, j in d.items():\n",
        "        sentence = sentence.replace(i, j)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "L8-nNFKJjyEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(Input_text):\n",
        "\n",
        "    '''\n",
        "    Inputs :\n",
        "        name    : Input_text\n",
        "        type    : str\n",
        "        content : text data (text file) \n",
        "    \n",
        "    Ouput : \n",
        "        name    : email_file \n",
        "        type    : list\n",
        "        content : list of strings\n",
        "\n",
        "        name    : subject_file \n",
        "        type    : list\n",
        "        content : list of strings\n",
        "\n",
        "        name    : text_file \n",
        "        type    : list\n",
        "        content : list of strings  \n",
        "\n",
        "    Process :\n",
        "        This function take input as python text file and using different methods\n",
        "        extract email, email subject and email text and preprocess it.\n",
        "    '''\n",
        "    \n",
        "\n",
        "    email_file = \" \"\n",
        "    subject_file = \"\"\n",
        "    text_file = [ ]\n",
        "    for line in Input_text:\n",
        "\n",
        "    ###### Email id preprocess ######\n",
        "\n",
        "        # extract email ids\n",
        "        email1 = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', line)\n",
        "        e = ''\n",
        "        for i in email1:\n",
        "            remove_email = re.sub(i, \"\", line)\n",
        "            email = i.split('@')[1]\n",
        "            email = \" \".join(email.split('.'))\n",
        "            email = re.sub('com|COM', \"\", email)\n",
        "            email = email if len(email) > 2 else \"\"\n",
        "            e += \" \" + email\n",
        "        \n",
        "        email_file += e\n",
        "\n",
        "    ###### Subject Text preprocess #####\n",
        "\n",
        "        subject1 = line if 'Subject:' in line else \"\"\n",
        "        subject = re.sub(\"\\n\", \"\", subject1)\n",
        "        subject = re.split('re:|Re:|Subject:|:', subject)\n",
        "        subject = \"\".join(subject[1:])\n",
        "        subject = re.sub('[^A-Za-z_]', ' ', subject)\n",
        "        subject = subject.strip(\" \")\n",
        "        subject_file += subject\n",
        "        line = line.replace(subject1,\"\")\n",
        "\n",
        "    ###### Email text preprocess ######\n",
        "\n",
        "        line = line if 'From:' not in line else \"\"\n",
        "        line = line if 'Write to:' not in line else \"\"\n",
        "\n",
        "        #Decontractions\n",
        "        line = re.sub(r\"won't\", \"will not\", line)\n",
        "        line = re.sub(r\"can\\'t\", \"can not\", line)\n",
        "        line = re.sub(r\"n\\'t\", \" not\", line)\n",
        "        line = re.sub(r\"\\'re\", \" are\", line)\n",
        "        line = re.sub(r\"\\'s\", \" is\", line)\n",
        "        line = re.sub(r\"\\'d\", \" would\", line)\n",
        "        line = re.sub(r\"\\'ll\", \" will\", line)\n",
        "        line = re.sub(r\"\\'t\", \" not\", line)\n",
        "        line = re.sub(r\"\\'ve\", \" have\", line)\n",
        "        line = re.sub(r\"\\'m\", \" am\", line)\n",
        "\n",
        "        #remove the word with end of \":\"\n",
        "        line = \"\".join(line.split(':')[1:]) if ':' in line else line\n",
        "        #remove the brackets and its context\n",
        "        line = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", line)\n",
        "        #remove the tags\n",
        "        line = re.sub('<.*?>', \"\", line)\n",
        "        #remove the special characters\n",
        "        line = re.sub('\\W+', \" \", line)\n",
        "        #remove extra space\n",
        "        line = \" \".join(line.split())\n",
        "        #remove the special characters\n",
        "        line = re.sub('\\W+', \" \", line)\n",
        "        #remove the special char\n",
        "        line = re.sub('[\\W\\_]',' ',line)\n",
        "        #find the grp place and split by '_'\n",
        "        line = split_loc(line)\n",
        "        #convert into the lowercase\n",
        "        line = line.lower()\n",
        "        #convert below form except \"\"\n",
        "        # line = re.sub('^[A-Za-z_]', '', line)\n",
        "        #remove the digits\n",
        "        remove_digits = str.maketrans('', '', digits)\n",
        "        line = line.translate(remove_digits)\n",
        "        #remove len(string) less than or equal to in string\n",
        "        line = \" \".join([i for i in line.split() if len(i) > 2 ])\n",
        "        text_file.append(line)\n",
        "\n",
        "    text_file = \" \".join(' '.join(text_file).split())\n",
        "\n",
        "    return (email_file.lower(), subject_file.lower(), text_file.lower())\n"
      ],
      "metadata": {
        "id": "2xY0R4CfjyBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_dir = os.listdir(\"/content/documents\")"
      ],
      "metadata": {
        "id": "NWD7tvSGtE5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' pre process text subject and email '''\n",
        "\n",
        "pre_process_text = [ ]\n",
        "pre_process_email = [ ]\n",
        "pre_process_subject = [ ]\n",
        "\n",
        "for text in tqdm(text_dir):\n",
        "    fileName = '/content/documents/' + str(text)\n",
        "    with open(fileName, 'r', encoding=' iso-8859-1') as file:\n",
        "        lines = file.readlines()\n",
        "        email, subject, text = process(lines)\n",
        "        pre_process_email.append(email)\n",
        "        pre_process_subject.append(subject)\n",
        "        pre_process_text.append(text)"
      ],
      "metadata": {
        "id": "x_ZltfjHs7vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = pd.DataFrame()\n",
        "text_df['text'] = pre_process_text\n",
        "text_df['email_id'] = pre_process_email\n",
        "text_df['subject'] = pre_process_subject"
      ],
      "metadata": {
        "id": "HqlKi0Sc6thg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' pre process raw text and labels '''\n",
        "\n",
        "raw_text = [ ]\n",
        "class_label = [ ]\n",
        "\n",
        "for text in tqdm(text_dir):\n",
        "\n",
        "    m = re.search('_', text)\n",
        "    label = text[: m.end()-1]\n",
        "    class_label.append(label)\n",
        "    fileName = '/content/documents/' + str(text)\n",
        "\n",
        "    with open(fileName, 'r', encoding=' iso-8859-1') as file:\n",
        "        \n",
        "        lines = file.readlines()\n",
        "        lines = \" \".join(' '.join(lines).split())\n",
        "        raw_text.append(lines)"
      ],
      "metadata": {
        "id": "CH9Asc15Ddg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['raw_text'] = raw_text\n",
        "text_df['class_label'] = class_label"
      ],
      "metadata": {
        "id": "Hr85I5swS8zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df"
      ],
      "metadata": {
        "id": "HztfNKtz7AAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "e9d2ccc0-f74e-4cdb-f166-26a7e5460bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0      his was posted the firearms politics mailing l...   \n",
              "1      having problem with truetype fonts windows hav...   \n",
              "2      does the radio electronics free information ca...   \n",
              "3      uppose have boolean function which minimal sum...   \n",
              "4      ello name john and have the following comic bo...   \n",
              "...                                                  ...   \n",
              "18823  ate begets more hate never love consider some ...   \n",
              "18824  article arromdee jyusenkyou jhu edu think many...   \n",
              "18825  ould some one tell what har lap err the chip c...   \n",
              "18826  abital planets are also dependent what kind pl...   \n",
              "18827  window package exists that runs dos would very...   \n",
              "\n",
              "                                                email_id  \\\n",
              "0                hound dazixca ingr  hound dazixca ingr    \n",
              "1              gandalf fl bs dlr de gandalf fl bs dlr de   \n",
              "2        panix  acsu buffalo edu ubvmsb cc buffalo ed...   \n",
              "3        carson u washington edu ringer cs utsa edu r...   \n",
              "4        iscsvax uni edu iscsvax uni edu iscsvax uni edu   \n",
              "...                                                  ...   \n",
              "18823      world std  athos rutgers edu prism gatech edu   \n",
              "18824    newton apple  blaze cs jhu edu jyusenkyou cs...   \n",
              "18825    spartan ac brocku ca nmt edu jupiter nmt edu...   \n",
              "18826    ucsu colorado edu aurora alaska edu aurora a...   \n",
              "18827                                       daimi aau dk   \n",
              "\n",
              "                                       subject  \\\n",
              "0                   randy weaver trail - day 3   \n",
              "1         truetype font mix-up times=>cyrillic   \n",
              "2      radio electronics free information card   \n",
              "3                      minimal boolean circuit   \n",
              "4                      ****comic book sale****   \n",
              "...                                        ...   \n",
              "18823                          hate the sin...   \n",
              "18824          yet more rushdie [ islamic law]   \n",
              "18825                       help!  phar lap???   \n",
              "18826                  human habitale planets?   \n",
              "18827                          x-window for pc   \n",
              "\n",
              "                                                raw_text  \\\n",
              "0      From: crphilli@hound.dazixca.ingr.com (Ron Phi...   \n",
              "1      From: FL2G@gandalf.fl.bs.dlr.de (Reiner Suikat...   \n",
              "2      From: schuster@panix.com (Michael Schuster) Su...   \n",
              "3      From: whit@carson.u.washington.edu (John Whitm...   \n",
              "4      From: oeth6050@iscsvax.uni.edu Subject: ****CO...   \n",
              "...                                                  ...   \n",
              "18823  From: pduggan@world.std.com (Paul C Duggan) Su...   \n",
              "18824  From: sandvik@newton.apple.com (Kent Sandvik) ...   \n",
              "18825  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...   \n",
              "18826  From: fcrary@ucsu.Colorado.EDU (Frank Crary) S...   \n",
              "18827  From: eks@daimi.aau.dk (Eigil Krogh S|rensen) ...   \n",
              "\n",
              "                    class_label  \n",
              "0            talk.politics.guns  \n",
              "1       comp.os.ms-windows.misc  \n",
              "2               sci.electronics  \n",
              "3               sci.electronics  \n",
              "4                  misc.forsale  \n",
              "...                         ...  \n",
              "18823    soc.religion.christian  \n",
              "18824               alt.atheism  \n",
              "18825  comp.sys.ibm.pc.hardware  \n",
              "18826                 sci.space  \n",
              "18827            comp.windows.x  \n",
              "\n",
              "[18828 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07a9cc89-6ca7-4e0e-b84c-7afeea5e1faa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>email_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>class_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>his was posted the firearms politics mailing l...</td>\n",
              "      <td>hound dazixca ingr  hound dazixca ingr</td>\n",
              "      <td>randy weaver trail - day 3</td>\n",
              "      <td>From: crphilli@hound.dazixca.ingr.com (Ron Phi...</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>having problem with truetype fonts windows hav...</td>\n",
              "      <td>gandalf fl bs dlr de gandalf fl bs dlr de</td>\n",
              "      <td>truetype font mix-up times=&gt;cyrillic</td>\n",
              "      <td>From: FL2G@gandalf.fl.bs.dlr.de (Reiner Suikat...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>does the radio electronics free information ca...</td>\n",
              "      <td>panix  acsu buffalo edu ubvmsb cc buffalo ed...</td>\n",
              "      <td>radio electronics free information card</td>\n",
              "      <td>From: schuster@panix.com (Michael Schuster) Su...</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uppose have boolean function which minimal sum...</td>\n",
              "      <td>carson u washington edu ringer cs utsa edu r...</td>\n",
              "      <td>minimal boolean circuit</td>\n",
              "      <td>From: whit@carson.u.washington.edu (John Whitm...</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ello name john and have the following comic bo...</td>\n",
              "      <td>iscsvax uni edu iscsvax uni edu iscsvax uni edu</td>\n",
              "      <td>****comic book sale****</td>\n",
              "      <td>From: oeth6050@iscsvax.uni.edu Subject: ****CO...</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18823</th>\n",
              "      <td>ate begets more hate never love consider some ...</td>\n",
              "      <td>world std  athos rutgers edu prism gatech edu</td>\n",
              "      <td>hate the sin...</td>\n",
              "      <td>From: pduggan@world.std.com (Paul C Duggan) Su...</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18824</th>\n",
              "      <td>article arromdee jyusenkyou jhu edu think many...</td>\n",
              "      <td>newton apple  blaze cs jhu edu jyusenkyou cs...</td>\n",
              "      <td>yet more rushdie [ islamic law]</td>\n",
              "      <td>From: sandvik@newton.apple.com (Kent Sandvik) ...</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18825</th>\n",
              "      <td>ould some one tell what har lap err the chip c...</td>\n",
              "      <td>spartan ac brocku ca nmt edu jupiter nmt edu...</td>\n",
              "      <td>help!  phar lap???</td>\n",
              "      <td>From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18826</th>\n",
              "      <td>abital planets are also dependent what kind pl...</td>\n",
              "      <td>ucsu colorado edu aurora alaska edu aurora a...</td>\n",
              "      <td>human habitale planets?</td>\n",
              "      <td>From: fcrary@ucsu.Colorado.EDU (Frank Crary) S...</td>\n",
              "      <td>sci.space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18827</th>\n",
              "      <td>window package exists that runs dos would very...</td>\n",
              "      <td>daimi aau dk</td>\n",
              "      <td>x-window for pc</td>\n",
              "      <td>From: eks@daimi.aau.dk (Eigil Krogh S|rensen) ...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18828 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07a9cc89-6ca7-4e0e-b84c-7afeea5e1faa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07a9cc89-6ca7-4e0e-b84c-7afeea5e1faa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07a9cc89-6ca7-4e0e-b84c-7afeea5e1faa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove special char from string\n",
        "text_df['subject'].replace({'[^A-Za-z_]' : ' '}, regex=True, inplace=True)"
      ],
      "metadata": {
        "id": "wYVefPtEbbWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df['combine'] = text_df['text'] + text_df[ 'subject'] + text_df['email_id']"
      ],
      "metadata": {
        "id": "6-qqGz8dTHw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "IihIoNF5dIlg",
        "outputId": "f13ebbe6-18bf-4e8e-aa78-364e0cfa0aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  \\\n",
              "0      his was posted the firearms politics mailing l...   \n",
              "1      having problem with truetype fonts windows hav...   \n",
              "2      does the radio electronics free information ca...   \n",
              "3      uppose have boolean function which minimal sum...   \n",
              "4      ello name john and have the following comic bo...   \n",
              "...                                                  ...   \n",
              "18823  ate begets more hate never love consider some ...   \n",
              "18824  article arromdee jyusenkyou jhu edu think many...   \n",
              "18825  ould some one tell what har lap err the chip c...   \n",
              "18826  abital planets are also dependent what kind pl...   \n",
              "18827  window package exists that runs dos would very...   \n",
              "\n",
              "                                                email_id  \\\n",
              "0                hound dazixca ingr  hound dazixca ingr    \n",
              "1              gandalf fl bs dlr de gandalf fl bs dlr de   \n",
              "2        panix  acsu buffalo edu ubvmsb cc buffalo ed...   \n",
              "3        carson u washington edu ringer cs utsa edu r...   \n",
              "4        iscsvax uni edu iscsvax uni edu iscsvax uni edu   \n",
              "...                                                  ...   \n",
              "18823      world std  athos rutgers edu prism gatech edu   \n",
              "18824    newton apple  blaze cs jhu edu jyusenkyou cs...   \n",
              "18825    spartan ac brocku ca nmt edu jupiter nmt edu...   \n",
              "18826    ucsu colorado edu aurora alaska edu aurora a...   \n",
              "18827                                       daimi aau dk   \n",
              "\n",
              "                                       subject  \\\n",
              "0                   randy weaver trail   day     \n",
              "1         truetype font mix up times  cyrillic   \n",
              "2      radio electronics free information card   \n",
              "3                      minimal boolean circuit   \n",
              "4                          comic book sale       \n",
              "...                                        ...   \n",
              "18823                          hate the sin      \n",
              "18824          yet more rushdie   islamic law    \n",
              "18825                       help   phar lap      \n",
              "18826                  human habitale planets    \n",
              "18827                          x window for pc   \n",
              "\n",
              "                                                raw_text  \\\n",
              "0      From: crphilli@hound.dazixca.ingr.com (Ron Phi...   \n",
              "1      From: FL2G@gandalf.fl.bs.dlr.de (Reiner Suikat...   \n",
              "2      From: schuster@panix.com (Michael Schuster) Su...   \n",
              "3      From: whit@carson.u.washington.edu (John Whitm...   \n",
              "4      From: oeth6050@iscsvax.uni.edu Subject: ****CO...   \n",
              "...                                                  ...   \n",
              "18823  From: pduggan@world.std.com (Paul C Duggan) Su...   \n",
              "18824  From: sandvik@newton.apple.com (Kent Sandvik) ...   \n",
              "18825  From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...   \n",
              "18826  From: fcrary@ucsu.Colorado.EDU (Frank Crary) S...   \n",
              "18827  From: eks@daimi.aau.dk (Eigil Krogh S|rensen) ...   \n",
              "\n",
              "                    class_label  \\\n",
              "0            talk.politics.guns   \n",
              "1       comp.os.ms-windows.misc   \n",
              "2               sci.electronics   \n",
              "3               sci.electronics   \n",
              "4                  misc.forsale   \n",
              "...                         ...   \n",
              "18823    soc.religion.christian   \n",
              "18824               alt.atheism   \n",
              "18825  comp.sys.ibm.pc.hardware   \n",
              "18826                 sci.space   \n",
              "18827            comp.windows.x   \n",
              "\n",
              "                                                 combine  \n",
              "0      his was posted the firearms politics mailing l...  \n",
              "1      having problem with truetype fonts windows hav...  \n",
              "2      does the radio electronics free information ca...  \n",
              "3      uppose have boolean function which minimal sum...  \n",
              "4      ello name john and have the following comic bo...  \n",
              "...                                                  ...  \n",
              "18823  ate begets more hate never love consider some ...  \n",
              "18824  article arromdee jyusenkyou jhu edu think many...  \n",
              "18825  ould some one tell what har lap err the chip c...  \n",
              "18826  abital planets are also dependent what kind pl...  \n",
              "18827  window package exists that runs dos would very...  \n",
              "\n",
              "[18828 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd6d9b32-ee92-4ed6-bcd8-d7a16b421185\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>email_id</th>\n",
              "      <th>subject</th>\n",
              "      <th>raw_text</th>\n",
              "      <th>class_label</th>\n",
              "      <th>combine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>his was posted the firearms politics mailing l...</td>\n",
              "      <td>hound dazixca ingr  hound dazixca ingr</td>\n",
              "      <td>randy weaver trail   day</td>\n",
              "      <td>From: crphilli@hound.dazixca.ingr.com (Ron Phi...</td>\n",
              "      <td>talk.politics.guns</td>\n",
              "      <td>his was posted the firearms politics mailing l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>having problem with truetype fonts windows hav...</td>\n",
              "      <td>gandalf fl bs dlr de gandalf fl bs dlr de</td>\n",
              "      <td>truetype font mix up times  cyrillic</td>\n",
              "      <td>From: FL2G@gandalf.fl.bs.dlr.de (Reiner Suikat...</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "      <td>having problem with truetype fonts windows hav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>does the radio electronics free information ca...</td>\n",
              "      <td>panix  acsu buffalo edu ubvmsb cc buffalo ed...</td>\n",
              "      <td>radio electronics free information card</td>\n",
              "      <td>From: schuster@panix.com (Michael Schuster) Su...</td>\n",
              "      <td>sci.electronics</td>\n",
              "      <td>does the radio electronics free information ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>uppose have boolean function which minimal sum...</td>\n",
              "      <td>carson u washington edu ringer cs utsa edu r...</td>\n",
              "      <td>minimal boolean circuit</td>\n",
              "      <td>From: whit@carson.u.washington.edu (John Whitm...</td>\n",
              "      <td>sci.electronics</td>\n",
              "      <td>uppose have boolean function which minimal sum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ello name john and have the following comic bo...</td>\n",
              "      <td>iscsvax uni edu iscsvax uni edu iscsvax uni edu</td>\n",
              "      <td>comic book sale</td>\n",
              "      <td>From: oeth6050@iscsvax.uni.edu Subject: ****CO...</td>\n",
              "      <td>misc.forsale</td>\n",
              "      <td>ello name john and have the following comic bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18823</th>\n",
              "      <td>ate begets more hate never love consider some ...</td>\n",
              "      <td>world std  athos rutgers edu prism gatech edu</td>\n",
              "      <td>hate the sin</td>\n",
              "      <td>From: pduggan@world.std.com (Paul C Duggan) Su...</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "      <td>ate begets more hate never love consider some ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18824</th>\n",
              "      <td>article arromdee jyusenkyou jhu edu think many...</td>\n",
              "      <td>newton apple  blaze cs jhu edu jyusenkyou cs...</td>\n",
              "      <td>yet more rushdie   islamic law</td>\n",
              "      <td>From: sandvik@newton.apple.com (Kent Sandvik) ...</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>article arromdee jyusenkyou jhu edu think many...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18825</th>\n",
              "      <td>ould some one tell what har lap err the chip c...</td>\n",
              "      <td>spartan ac brocku ca nmt edu jupiter nmt edu...</td>\n",
              "      <td>help   phar lap</td>\n",
              "      <td>From: tmc@spartan.ac.BrockU.CA (Tim Ciceran) S...</td>\n",
              "      <td>comp.sys.ibm.pc.hardware</td>\n",
              "      <td>ould some one tell what har lap err the chip c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18826</th>\n",
              "      <td>abital planets are also dependent what kind pl...</td>\n",
              "      <td>ucsu colorado edu aurora alaska edu aurora a...</td>\n",
              "      <td>human habitale planets</td>\n",
              "      <td>From: fcrary@ucsu.Colorado.EDU (Frank Crary) S...</td>\n",
              "      <td>sci.space</td>\n",
              "      <td>abital planets are also dependent what kind pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18827</th>\n",
              "      <td>window package exists that runs dos would very...</td>\n",
              "      <td>daimi aau dk</td>\n",
              "      <td>x window for pc</td>\n",
              "      <td>From: eks@daimi.aau.dk (Eigil Krogh S|rensen) ...</td>\n",
              "      <td>comp.windows.x</td>\n",
              "      <td>window package exists that runs dos would very...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18828 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd6d9b32-ee92-4ed6-bcd8-d7a16b421185')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd6d9b32-ee92-4ed6-bcd8-d7a16b421185 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd6d9b32-ee92-4ed6-bcd8-d7a16b421185');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check nan values in dataset\n",
        "text_df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wt5nvuAye3oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEfQPV2Ce9ou",
        "outputId": "9ab46118-0d27-41a5-f2c6-b6edb3e2c1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18789, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df.to_csv(\"/content/drive/MyDrive/email_data_preprocess2.csv\", index=False)"
      ],
      "metadata": {
        "id": "00rKdpoqbMv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsqvTQhcgtwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaxXK9AWgttF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}